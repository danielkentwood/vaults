# Retrieval Augmented Generation

##### Metadata
created:: 2023-11-09 16:39
modified:: <%+ tp.file.last_modified_date() %>
mode: #mode/gnosis
kind:: #zettel 
status:: #status/seed
parent:: [[LLM]]
***






## External Resources
- [LongLLMLingua -- prompt compression](https://blog.llamaindex.ai/longllmlingua-bye-bye-to-middle-loss-and-save-on-your-rag-costs-via-prompt-compression-54b559b9ddf7)
	- "A big issue with RAG is that stuffing more context â‰  better. This both costs money ðŸ’¸ and leads to lost in the middle problems ðŸš« LongLLMLingua is a prompt compression method that solves both problems: boost accuracy by 20% while using ~25% of the tokens ðŸ”¥ OurÂ [LlamaIndex](https://www.linkedin.com/company/llamaindex/)Â integration lets you easily plug it into your RAG pipeline"
- [How to implement Weaviate RAG applications with Local LLMs and Embedding models](https://bratanic-tomaz.medium.com/how-to-implement-weaviate-rag-applications-with-local-llms-and-embedding-models-24a9128eaf84)
- [Implementing advanced RAG strategies with Neo4j](https://blog.langchain.dev/implementing-advanced-retrieval-rag-strategies-with-neo4j/)
- When should you do prompt engineering to optimize RAG? 
	- Optimizing Prompts:Â [https://lnkd.in/dHtDuyv8](https://lnkd.in/dHtDuyv8)Â   
	- Full Prompt Module Hub:Â [https://lnkd.in/dDrG9EMT](https://lnkd.in/dDrG9EMT)Â   
	- Prompt Engineering for RAG:Â [https://lnkd.in/ddmXiN9t](https://lnkd.in/ddmXiN9t)
- [Using a knowledge graph to implement a devops RAG application](https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/)
- [Mastering RAG: How to Architect an Enterprise RAG System](https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system)
