# Gradient boosting

Level: 1
Tags: [[decision tree]]

Gradient boosting combines multiple weak "learners" into a single strong learner in an iterative fashion.

Suppose you have a least-squares regression problem, and you want to perform gradient boosting. 

First, select the number of $M$ stages (i.e., number of iterations for boosting). 

Examples:
* [[xgBoost]]
* [[LightGBM]]


![Gradient%20boosting%20bb929c9c6fa04b088f5c6301b6800187/Untitled.png](Untitled%2016.png)

**XGBoost**

![Gradient%20boosting%20bb929c9c6fa04b088f5c6301b6800187/Untitled%201.png](Untitled%201%205.png)

